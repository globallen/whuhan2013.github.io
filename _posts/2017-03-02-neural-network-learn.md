---
layout: post
title: 神经网络结构与神经元激励函数
date: 2017-3-2
categories: blog
tags: [计算机视觉]
description: 计算机视觉
---


**单个神经元建模**

神经网络算法领域最初是被对生物神经系统建模这一目标启发，但随后与其分道扬镳，成为一个工程问题，并在机器学习领域取得良好效果。我们可以这么理解这个模型：在信号的传导过程中，突触可以控制传导到下一个神经元的信号强弱(数学模型中的权重w)，而这种强弱是可以学习到的。在我们简化的数学计算模型中，我们假定有一个『激励函数』来控制加和的结果对神经元的刺激程度，从而控制着是否激活神经元和向后传导信号

#### 作为线性分类器的单个神经元

神经元模型的前向计算数学公式看起来可能比较眼熟。就像在线性分类器中看到的那样，神经元有能力“喜欢”（激活函数值接近1），或者不喜欢（激活函数值接近0）输入空间中的某些线性区域。因此，只要在神经元的输出端有一个合适的损失函数，就能让单个神经元变成一个线性分类器。

![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter5/p1.png)

**对于正则化的解释**           
对于正则化的损失函数(不管是SVM还是Softmax)，其实我们在神经元的生物特性上都能找到对应的解释，我们可以将其(正则化项的作用)视作信号在神经元传递过程中的逐步淡化/衰减(gradual forgetting)，因为正则化项的作用是在每次迭代过程中，控制住权重w的幅度，往0上靠拢。

单个神经元的作用，可视作完成一个二分类的分类器(比如Softmax或者SVM分类器)

#### 常用激励函数

每一次输入和权重w线性组合之后，都会通过一个激励函数(也可以叫做非线性激励函数)，经非线性变换后输出。实际的神经网络中有一些可选的激励函数，我们一一说明一下最常见的几种：

**sigmoid**          
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter5/p2.jpeg)


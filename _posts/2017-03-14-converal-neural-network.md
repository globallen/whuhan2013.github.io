---
layout: post
title: 卷积神经网络
date: 2017-3-14
categories: blog
tags: [计算机视觉]
description: 计算机视觉
---

本文内容如下：  

- 结构概述
- 用来构建卷积神经网络的各种层
  + 卷积层
  + 汇聚层
  + 归一化层
  + 全连接层
  + 将全连接层转化成卷积层
- 卷积神经网络的结构
  + 层的排列规律
  + 层的尺寸设置规律
  + 案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）
  + 计算上的考量
- 拓展资源

**卷积神经网络（CNNs / ConvNets）**        
卷积神经网络是由神经元组成，神经元中有具有学习能力的权重和偏差。每个神经元都得到一些输入数据，进行内积运算后再进行激活函数运算。整个网络依旧是一个可导的评分函数：该函数的输入是原始的图像像素，输出是不同类别的评分。在最后一层（往往是全连接层），网络依旧有一个损失函数（比如SVM或Softmax），并且在神经网络中我们实现的各种技巧和要点依旧适用于卷积神经网络。

那么有哪些地方变化了呢？卷积神经网络的结构基于一个假设，即输入数据是图像，基于该假设，我们就向结构中添加了一些特有的性质。这些特有属性使得前向传播函数实现起来更高效，并且大幅度降低了网络中参数的数量。


**结构概述**        
我们前面讲过的神经网络结构都比较一致，输入层和输出层中间夹着数层隐藏层，每一层都由多个神经元组成，层和层之间是全连接的结构，同一层的神经元之间没有连接。

卷积神经网络是上述结构的一种特殊化处理，因为对于图像这种数据而言，上面这种结构实际应用起来有较大的困难：就拿CIFAR-10举例吧，图片已经很小了，是32*32*3(长宽各32像素，3个颜色通道)的，那么在神经网络当中，我们只看隐藏层中的一个神经元，就应该有32*32*3=3072个权重，如果大家觉得这个权重个数的量还行的话，再设想一下，当这是一个包含多个神经元的多层神经网(假设n个)，再比如图像的质量好一点(比如是200*200*3的)，那将有200*200*3*n= 120000n个权重需要训练，结果是拉着这么多参数训练，基本跑不动，跑得起来也是『气喘吁吁』，当然，最关键的是这么多参数的情况下，分分钟模型就过拟合了。别急，别急，一会儿我们会提到卷积神经网络的想法和简化之处。

卷积神经网络结构比较固定的原因之一，是图片数据本身的合理结构，类图像结构(200*200*3)，我们也把卷积神经网络的神经元排布成 width*height*depth的结构，也就是说这一层总共有width*height*depth个神经元(这里的深度指的是激活数据体的第三个维度，而不是整个网络的深度，整个网络的深度指的是网络的层数），如下图所示。举个例子说，CIFAR-10中的图像是作为卷积神经网络的输入，该数据体的维度是32x32x3（宽度，高度和深度）,CIFAR-10的输出层就是1*1*10维的。另外我们后面会说到，每一层的神经元，其实只和上一层里某些小区域进行连接，而不是和上一层每个神经元全连接。 

![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p1.jpeg)

#### 卷积神经网络的组成层
在卷积神经网络中，有3种最主要的层,一个简单的卷积神经网络是由各种层按照顺序排列组成，网络中的每个层使用一个可以微分的函数将激活数据从一个层传递到另一个层。

- 卷积运算层
- 汇聚(pooling)层
- 全连接层

一个完整的神经网络就是由这三种层叠加组成的。         

网络结构例子：这仅仅是个概述，下面会更详解的介绍细节。一个用于CIFAR-10图像数据分类的卷积神经网络的结构可以是[输入层-卷积层-ReLU层-汇聚层-全连接层]。细节如下：

- 输入[32x32x3]存有图像的原始像素值，本例中图像宽高均为32，有3个颜色通道。
- 卷积层中，神经元与输入层中的一个局部区域相连，每个神经元都计算自己与输入层相连的小区域与自己权重的内积。卷积层会计算所有神经元的输出。如果我们使用12个滤波器（也叫作核），得到的输出数据体的维度就是[32x32x12]。
- ReLU层将会逐个元素地进行激活函数操作，比如使用以0为阈值的max(0,x)作为激活函数。该层对数据尺寸没有改变，还是[32x32x12]。
- 汇聚层在在空间维度（宽度和高度）上进行降采样（downsampling）操作，数据尺寸变为[16x16x12]。
- 全连接层将会计算分类评分，数据尺寸变为[1x1x10]，其中10个数字对应的就是CIFAR-10中10个类别的分类评分值。正如其名，全连接层与常规神经网络一样，其中每个神经元都与前一层中所有神经元相连接。

由此看来，卷积神经网络一层一层地将图像从原始像素值变换成最终的分类评分值。其中有的层含有参数，有的没有。具体说来，卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数（神经元的突触权值和偏差）。而ReLU层和汇聚层则是进行一个固定不变的函数操作。卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了。

小结：

- 简单案例中卷积神经网络的结构，就是一系列的层将输入数据变换为输出数据（比如分类评分）。
- 卷积神经网络结构中有几种不同类型的层（目前最流行的有卷积层、全连接层、ReLU层和汇聚层）。
- 每个层的输入是3D数据，然后使用一个可导的函数将其变换为3D的输出数据。
- 有的层有参数，有的没有（卷积层和全连接层有，ReLU层和汇聚层没有）。
- 有的层有额外的超参数，有的没有（卷积层、全连接层和汇聚层有，ReLU层没有）。

![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p2.jpg)

#### 卷积层       
卷积层是构建卷积神经网络的核心层，它产生了网络中大部分的计算量         
**卷积层综述**          
直观看来，卷积层的参数其实可以看做，一系列的可训练/学习的过滤器。在前向计算过程中，我们输入一定区域大小(width*height)的数据，和过滤器点乘后等到新的二维数据，然后滑过一个个滤波器，组成新的3维输出数据。而我们可以理解成每个过滤器都只关心过滤数据小平面内的部分特征，当出现它学习到的特征的时候，就会呈现激活/activate态。           

局部关联度。这是卷积神经网络的独特之处其中之一，我们知道在高维数据(比如图片)中，用全连接的神经网络，实际工程中基本是不可行的。卷积神经网络中每一层的神经元只会和上一层的一些局部区域相连，这就是所谓的局部连接性。你可以想象成，上一层的数据区，有一个滑动的窗口，只有这个窗口内的数据会和下一层神经元有关联，当然，这个做法就要求我们手动敲定一个超参数:窗口大小。通常情况下，这个窗口的长和宽是相等的，我们把长x宽叫做receptive field。实际的计算中，这个窗口是会『滑动』的，会近似覆盖图片的所有小区域。

举个实例，CIFAR-10中的图片输入数据为[32*32*3]的，如果我们把receptive field设为5*5，那receptive field的data都会和下一层的神经元关联，所以共有5*5*3=75个权重，注意到最后的3依旧代表着RGB 3个颜色通道。

如果不是输入数据层，中间层的data格式可能是[16*16*20]的，假如我们取3*3的receptive field，那单个神经元的权重为3*3*20=180。
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p3.jpeg)
局部关联细节。我们刚才说到卷积层的局部关联问题，这个地方有一个receptive field，也就是我们直观理解上的『滑动数据窗口』。从输入的数据到输出数据，有三个超参数会决定输出数据的维度，分别是深度/depth，步长/stride 和 填充值/zero-padding：

- 所谓深度/depth，简单说来指的就是卷积层中和上一层同一个输入区域连接的神经元个数,它和使用的滤波器的数量一致，而每个滤波器在输入数据中寻找一些不同的东西。。这部分神经元会在遇到输入中的不同feature时呈现activate状态，举个例子，如果这是第一个卷积层，那输入到它的数据实际上是像素值，不同的神经元可能对图像的边缘。轮廓或者颜色会敏感。
- 所谓步长/stride，是指的窗口从当前位置到下一个位置，『跳过』的中间数据个数。比如从图像数据层输入到卷积层的情况下，也许窗口初始位置在第1个像素，第二个位置在第5个像素，那么stride=5-1=4.
- 所谓zero-padding是在原始数据的周边补上0值的圈数。(下面第2张图中的样子)       

这么解释可能理解起来还是会有困难，我们找两张图来对应一下这三个量：         
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p4.jpeg)
这是解决ImageNet分类问题用到的卷积神经网络的一部分，我们看到卷积层直接和最前面的图像层连接。图像层的维度为[227*227*3]，而receptive field设为11*11，图上未标明，但是滑动窗口的步长stride设为4，深度depth为48+48=96(这是双GPU并行设置)，边缘没有补0，因此zero-padding为0，因此窗口滑完一行，总共停留次数为(data_len-receptive_field_len+2*zero-padding)/stride+1=(227-11+2*0)/4+1=55，因为图像的长宽相等，因此纵向窗口数也是55，最后得到的输出数据维度为55*55*96维。
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p5.gif)
这是一张动态的卷积层计算图，图上的zero-padding为1，所以大家可以看到数据左右各补了一行0，窗口的长宽为3，滑动步长stride为2。

关于zero-padding，补0这个操作产生的根本原因是，为了保证窗口的滑动能从头刚好到尾。举个例子说，上2图中的上面一幅图，因为(data_len-receptive_field_len+2*zero-padding)/stride刚好能够整除，所以窗口左侧贴着数据开始位置，滑到尾部刚好窗口右侧能够贴着数据尾部位置，因此是不需要补0的。而在下面那幅图中，如果滑动步长设为4，你会发现第一次计算之后，窗口就无法『滑动』了，而尾部的数据，是没有被窗口『看到过』的，因此补0能够解决这个问题。

关于窗口滑动步长。大家可以发现一点，窗口滑动步长设定越小，两次滑动取得的数据，重叠部分越多，但是窗口停留的次数也会越多，运算律大一些；窗口滑动步长设定越长，两次滑动取得的数据，重叠部分越少，窗口停留次数也越少，运算量小，但是从一定程度上说数据信息不如上面丰富了。

**卷积层的参数共享**         
首先得说卷积层的参数共享是一个非常赞的处理方式，它使得卷积神经网络的训练计算复杂度和参数个数降低非常非常多。就拿实际解决ImageNet分类问题的卷积神经网络结构来说，我们知道输出结果有55*55*96=290400个神经元，而每个神经元因为和窗口内数据的连接，有11*11*3=363个权重和1个偏移量。所以总共有290400*364=105705600个权重。。。然后。。。恩，训练要累挂了。。。

因此我们做了一个大胆的假设，我们刚才提到了，每一个神经元可以看做一个filter，对图片中的数据窗区域做『过滤』。那既然是filter，我们干脆就假设这个神经元用于连接数据窗的权重是固定的，这意味着，对同一个神经元而言，不论上一层数据窗口停留在哪个位置，连接两者之间的权重都是同一组数。那代表着，上面的例子中的卷积层，我们只需要 神经元个数*数据窗口维度=96*11*11*3=34848个权重。

如果对应每个神经元的权重是固定的，那么整个计算的过程就可以看做，一组固定的权重和不同的数据窗口数据做内积的过程，这在数学上刚好对应『卷积』操作，这也就是卷积神经网的名字来源。另外，因为每个神经元的权重固定，它可以看做一个恒定的filter，比如上面96个神经元作为filter可视化之后是如下的样子：
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p6.jpeg)
需要说明的一点是，参数共享这个策略并不是每个场景下都合适的。有一些特定的场合，我们不能把图片上的这些窗口数据都视作作用等同的。一个很典型的例子就是人脸识别，一般人的面部都集中在图像的中央，因此我们希望，数据窗口滑过这块区域的时候，权重和其他边缘区域是不同的。我们有一种特殊的层对应这种功能，叫做局部连接层/Locally-Connected Layer

**卷积层的简单numpy实现**        
我们假定输入到卷积层的数据为X，加入X的维度为X.shape: (11,11,4)。假定我们的zero-padding为0，也就是左右上下不补充0数据，数据窗口大小为5，窗口滑动步长为2。那输出数据的长宽应该为(11-5)/2+1=4。假定第一个神经元对应的权重和偏移量分别为W0和b0，那我们就能算得，在第一行数据窗口停留的4个位置，得到的结果值分别为：

```
V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0
V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0
V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0
V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0
```

注意上述计算过程中，*运算符是对两个向量进行点乘的，因此W0应该维度为(5,5,4)，同样你可以计算其他位置的计算输出值：

```
V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1
V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1
V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1
V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1
V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 （在y方向上）
V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 （或两个方向上同时）
```

每一个神经元对应不同的一组W和b，在每个数据窗口停留的位置，得到一个输出值。

我们之前提到了卷积层在做的事情，是不断做权重和窗口数据的点乘和求和。因此我们也可以把这个过程整理成一个大的矩阵乘法。

- 看看数据端，我们可以做一个操作im2col将数据转成一个可直接供神经元filter计算的大矩阵。举个例子说，输入是[227*227*3]的图片，而神经元权重为[11*11*3]，同时窗口移动步长为4，那我们知道数据窗口滑动过程中总共产生[(227-11)/4+1]*[(227-11)/4+1]=55*55=3025个局部数据区域，又每个区域包含11*11*3=363个数据值，因此我们想办法把原始数据重复和扩充成一个[363*3025]的数据矩阵X_col，就可以直接和filter进行运算了。
- 对于filter端(卷积层)，假如厚度为96(有96个不同权重组的filter)，每个filter的权重为[11*11*3]，因此filter矩阵W_row维度为[96*363]
- 在得到上述两个矩阵后，我们的输出结果即可以通过np.dot(W_row, X_col)计算得到，结果数据为[96*3025]维的。

这个实现的弊端是，因为数据窗口的滑动过程中有重叠，因此我们出现了很多重复数据，占用内存较大。好处是，实际计算过程非常简单，如果我们用类似BLAS这样的库，计算将非常迅速。

另外，在反向传播过程中，其实卷积对应的操作还是卷积，因此实现起来也很方便。

#### Pooling层

简单说来，在卷积神经网络中，Pooling层是夹在连续的卷积层中间的层。它的作用也非常简单，就是**逐步地压缩/减少数据和参数的量，也在一定程度上减小过拟合的现象。**Pooling层做的操作也非常简单，就是将原数据上的区域压缩成一个值(区域最大值/MAX或者平均值/AVERAGE)，最常见的Pooling设定是，将原数据切成2*2的小块，每块里面取最大值作为输出，这样我们就自然而然减少了75%的数据量。需要提到的是，除掉MAX和AVERAGE的Pooling方式，其实我们也可以设定别的pooling方式，比如L2范数pooling。说起来，历史上average pooling用的非常多，但是近些年热度降了不少，工程师们在实践中发现max pooling的效果相对好一些。
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p7.jpeg)
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter10/p8.jpeg)
上图为Pooling层的一个直观示例，相当于对厚度为64的data，每一个切片做了一个下采样。下图为Pooling操作的实际max操作。

Pooling层(假定是MAX-Pooling)在反向传播中的计算也是很简单的，大家都知道如何去求max(x,y)函数的偏导。

#### 归一化层(Normalization Layer)       
卷积神经网络里面有时候会用到各种各样的归一化层，尤其是早期的研究，经常能见到它们的身影，不过近些年来的研究表明，似乎这个层级对最后结果的帮助非常小，所以后来大多数时候就干脆拿掉了。

#### 全连接层
这是我们在介绍神经网络的时候，最标准的形式，任何神经元和上一层的任何神经元之间都有关联，然后矩阵运算也非常简单和直接。现在的很多卷积神经网络结构，末层会采用全连接去学习更多的信息。




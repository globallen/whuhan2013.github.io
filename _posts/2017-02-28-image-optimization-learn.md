---
layout: post
title: 计算机视觉之最优化与随机梯度下降
date: 2017-2-28
categories: blog
tags: [计算机视觉]
description: 计算机视觉
---


在上一节中，我们介绍了图像分类任务中的两个关键部分：          

- 用于把原始像素信息映射到不同类别得分的得分函数/score function
- 用于评估参数W效果(评估该参数下每类得分和实际得分的吻合度)的损失函数/loss function

其中对于线性SVM，我们有：      
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter3/p1.png)  

在取到合适的参数W的情况下，我们根据原始像素计算得到的预测结果和实际结果吻合度非常高，这时候损失函数得到的值就很小。

这节我们就讲讲，怎么得到这个合适的参数W，使得损失函数取值最小化。也就是最优化的过程。

**损失函数可视化**                            

我们在计算机视觉中看到的损失函数，通常都是定义在非常高维的空间里的(比如CIFAR-10的例子里一个线性分类器的权重矩阵W是10 x 3073维的，总共有30730个参数 -_-||)，人要直接『看到』它的形状/变化是非常困难的。但是机智的同学们，总是能想出一些办法，把损失函数在某种程度上可视化的。比如说，我们可以把高维投射到一个向量/方向(1维)或者一个面(2维)上，从而能直观地『观察』到一些变化。    

举个例子说，我们可以对一个权重矩阵W(例如CIFAR−10中是30730个参数)，可以找到W维度空间中的一条直线，然后沿着这条线，计算一下损失函数值的变化情况。具体一点说，就是我们找到一个方向W1(维度要和W一样，才能表示W的维度空间的一个方向/一条直线)，然后我们给不同的a值，计算L(W+aW1)，这样，如果a取得足够密，其实我们就能够在一定程度上描绘出损失函数沿着这个方向的变化了。

同样，如果我们给两个方向W1和W2，那么我们可以确定一个平面，我们再取不同值的a和b，计算L(W+aW1+bW2)的值，那么我们就可以大致绘出在这个平面上，损失函数的变化情况了。

根据上面的方法，我们画出了下面3个图。最上面的图是调整a的不同取值，绘出的损失函数变化曲线(越高值越大)；中间和最后一个图是调整a与b的取值，绘出的损失函数变化图(蓝色表示损失小，红色表示损失大)，中间是在一个图片样本上计算的损失结果，最下图为100张图片上计算的损失结果的一个平均。显然沿着直线方向得到的曲线底端为最小的损失值点，而曲面呈现的碗状图形碗底为损失函数取值最小处。 

![](https://raw.githubusercontent.com/whuhan2013/myImage/master/cs231n/chapter3/p2.jpg)       

我们从数学的角度，来尝试解释一下，上面的凹曲线是怎么出来的。对于第i个样本，我们知道它的损失函数值为： 



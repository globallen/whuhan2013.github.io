---
layout: post
title: 图像特征提取
date: 2017-1-2
categories: blog
tags: [图像处理]
description: 特征提取
---

从本节开始， 我们将逐步从数字图像处理向图像识别过渡。 严格地说， 图像特征提取属于图像分析的范畴， 是数字图像处理的高级阶段， 同时也是图像识别的开始。

**本文主要包括以下内容**       

- 常用的基本统计特征， 如周长、面积、均值等区域描绘子， 以及直方图和灰度共现矩阵等纹理描绘子
- 主成份分析(PCA, PrincipaJ Component Analysis)
- 局部二进制模式(LBP, LocaJ Binary Pattern)
- 本章的典型案例分析
  + 基于PCA技术的人脸数据集的降维处理

### 图像特征概述    
众所周知，计算机不认识图像,只认识数字。为了使计算机能够“理解”图像，从而具有真正意义上的“视觉”，本章我们将研究如何从图像中提取有用的数据或信息，得到图像的“非图像” 的表示或描述，如数值、向量和符号等。这一过程就是特征提取，而提取出来的这些“非图像”的表示或描述就是特征。有了这些数值或向量形式的特征我们就可以通过训练过程教会计算机如何懂得这些特征， 从而使计算机具有识别图像的本领。      

**什么是图像特征**        
特征是某一类对象区别于其他类对象的相应（本质）特点或特性， 或是这些特点和特性的集合。特征是通过测量或处理能够抽取的数据。对于图像而言， 每一幅图像都具有能够区别于其他类图像的自身特征，有些是可以直观地感受到的自然特征，如亮度、边缘、纹理和色彩等；有些则是需要通过变换或处理才能得到的， 如矩、直方图以及主成份等。          

**特征向量及其几何解释**     
我们常常将某一类对象的多个或多种特性组合在一起， 形成一个特征向量来代表该类对象，如果只有单个数值特征，则特征向量为一个一维向量，如果是n个特性
的组合，则为一个n维特征向量。该类特征向量常常作为识别系统的输入。实际上，一个n维特征就是位于n维空间中的点，而识别分类的任务就是找到对这个n维空
间的一种划分。     
例如要区分3种不同的鸾尾属植物，可以选择其花瓣长度和花瓣宽度作为特征，这样就以1个2维特征代表1个植物对象，比如(5.1,3.5).如果再加上萼片长度和萼片宽度， 则每个鸾尾属植物对象由一个4维特征向置表示， 如(5.1, 3.5.1.4, 0.2)。

**特征提取的一般原则**     
图像识别实际上是一个分类的过程，为了识别出某图像所属的类别，我们需要将它与其他不同类别的图像区分开来。这就要求选取的特征不仅要能够很好地描述图像， 更重要的是还要能够很好地区分不同类别的图像。         
我们希望选择那些在同类图像之间差异较小（较小的类内距），在不同类别的图像之间差异较大（较大的类间距）的图像特征， 我们称之为最具有区分能力(most discriminative)的特征。此外， 在特征提取中先验知识扮演着重要的角色， 如何依靠先验知识来帮助我们选择特征也是后面将持续关注的问题。   

**特征的评价标准**    
一般来说，特征提取应具体问题具体分析，其评价标准具有一定的主观性。然而，还是有一些可供遵循的普遍原则，能够作为我们在特征提取实践中的指导。总结如下。   

- 特征应当容易提取． 换言之， 为了得到这些特征我们付出的代价不能太大． 当然， 这还要与特征的分类能力权衡考虑．
- 选取的特征应对噪声和不相关转换不敏感． 比如要识别车牌号码， 车牌照片可能是从各个角度拍摄的， 而我们关心的是车牌上字母和数字的内容， 因此就需要得到对几何失真变形等转换不敏感的描绘子， 从而得到旋转不变， 或是投影失真不变的特征．       
- 最重要的一点， 总是应试图寻找最具区分能力的特征．     

### 基本统计特征     
本节将主要介绍一些常用的基本统计特征， 包括一些简单的区域描绘子， 直方图及其统计特征， 以及灰度共现矩阵等.         

#### 简单的区域描绘子及其Matlab实现     
在经过图像分割得到各种我们感兴趣的区域之后，可以利用下面介绍的一些简单区域描绘子作为代表该区域的特征。通常将这些区域特征组合成特征向量以供分类使用。          

常用的简单区域描绘子如下。

- 周长：区域边界的长度， 即位于区域边界上的像素数目．
- 面积：， 区域中的像素总数．
- 致密性：（周长） 2/面积．
- 区域的质心．
- 灰度均值： 区域中所有像素的平均值．
- 灰度中值： 区域中所有像素的排序中值．
- 包含区域的最小矩形．
- 最小或最大灰度级．
- 大于或小于均值的像素数．
- 欧拉数： 区域中的对象数减去这些对象的孔洞数。    

在Matlab中， 函数regionprops用于计算区域描绘子的有利工具， 其原型为：     
D = regionprops(L,properties)        
L是一个标记矩阵， 可通过8.3.4小节介绍的连通区标注函数bwlabel得到．       
properties可以是一个用逗号分割的字符串列表， 其一些常用取值如表10.1所示    
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p1.png)    

利用regionprops函数提取简单的区域特征     

```
I = imread('bw_mouth.bmp');
I1 = bwlabel(I);
D = regionprops(I1,'area','centroid');
D.Area
```

#### 直方图及其统计特征     
首先来看纹理的概念。纹理是图像固有的特征之一，是灰度（对彩色图像而言是颜色）在空间以一定的形式变换而产生的图案（模式），有时具有一定的周期性。既然纹理区域的像素灰度级分布具有一定的形式，而直方图正是描述图像中像素灰度级分布的有力工具， 因此用直方图来描述纹理就顺理成章了。        

毫无疑问，相似的纹理具有相似的直方图；而由图10.2可见，3种不同特点的纹理对应3种不同的直方图。这说明直方图与纹理之间存在着一定的对应关系。因此，我们可以用直 方图或其统计特征作为图像纹理特征。直方图本身就是一个向量，向量的维数是直方图统计 的灰度级数，因此我们可以直接以此向量作为代表图像纹理的样本特征向量，从而交给分类器处理，对于LBP直方图就常常这样处理（见10.5节）；另一种思路是进一步从直方图中提取出能够很好地描述直方图的统计特征，将直方图的这些统计特征组合成为样本特征向量， 这样做可以大大降低特征向量的维数。         

直方图的常用统计特征如下所述。     
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p2.png) 
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p3.png) 
一个由均值、标准差、平滑度和熵组合而成的特征向量如：v = (m,a, R, e)。          
应认识到直方图及其统计特征是一种区分能力相对较弱的特征，这主要因为直方图属于一阶统计特征，而它们的一阶统计特征是无法反映纹理结构的变化的。直方图与纹理的对应关系并不是一对一的：首先，不同的纹理可能具有相同或相似的直方图，如图10.3所示的两种截然不同的图案就具有完全相同的直方图；其次，即便是两个不同的直方m.也可能具有相同的统计特 征如均值、标准差等。因此，依靠直方图及其统计特征来作为分类特征时需要特别注意。

### 灰度共现矩阵      
我们说灰度直方图是一种描述单个像素灰度分布的一阶统计量；而灰度共现矩阵描述的则是具有某种空间位置关系的两个像素的联合分布，可以看成是两个像素灰度对的联合直方图，是种二阶统计量。      
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p4.png) 
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p5.png)     
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p6.png)
由于灰度共现矩阵总共含有LXL个元素，当灰度级L比较大时它将是一个庞大的方阵。如对于一般的256灰度图，凡就是一个256X256的矩阵，共$2^16$ 个元素。如此庞大的矩阵将使后续的计算量剧增。因此普通灰度图像通常要经过处理以减少灰度级数，而后再计算灰度共现矩阵。可以通过分析纹理图像的直方图，在尽量不影响纹理质量的情况下．通过适当的灰度变换来达到灰度级压缩的目的。      

### 特征降维     

**维度灾难**    
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p7.png)
最大值时，分类器的性能不是得到改善，而是退化。这种现象正是在模式识别中被称为“维度灾难”的一种表现形式。例如，我们要区分西瓜和冬瓜，表皮的纹理和长宽比例都是很好 的特征，还可以再加上瓜籽的颜色以辅助判断，然而继续加入重量、体积等特征可能是无益 的，甚至还会对分类造成干扰。     
基于以上所述原因，降维对我们产生了巨大的吸引力。在低维空间中计算和分类都将变 得简单很多，训练（教授分类器如何区分不同类样本的过程，详见第11章）所需的样本数目也会大大降低。通过选择好的特征，摒弃坏的特征(10.3.2特征选择），将有助于分类器性能的提升；在通过组合特征降维时，在绝大多数情况下，丢弃某些特征所损失的信息通过在低 维空间中更加精确的映射(10.3.3特征抽取）可以得到补偿。         

具体来说，降低维度又存在着两种方法：特征选择和特征抽取。如图10.8所示，特征选择是指选择全部特征的一个子集作为特征向量：特征抽取是指通过已有特征的组合建立一个 新的特征子集，10.3.2小节将要介绍的主成份分析方法(principa1component analysis, PCA)就是通过原特征的线性组合建立新的特征子集的一种特征抽取方法。         

#### 特征选择简介      
重新回到10.1.3小节那个鸾尾属植物的问题。对于每一个莺尾属植物样本，总共有4个属性可以使用一一花瓣长度、花瓣宽度、萼片长度和萼片宽度。我们的目的是从中选择两个属性组成特征向量用于分类这3种鸾尾属植物。下面的Matlab程序选择了不同的特征子集，并给出了在对应特征空间中样本分布的可视化表示。  

```
load fisheriris;
data = [meas(:,1),meas(:,2)];
figure;
scatter(data(1:50,1),data(1:50,2),'b+');
hold on,scatter(data(51:100,1),data(51:100,2),'r*');
hold on,scatter(data(101:150,1),data(101:150,2),'go');

data = [meas(:,1),meas(:,3)];
figure;
scatter(data(1:50,1),data(1:50,2),'b+');
hold on,scatter(data(51:100,1),data(51:100,2),'r*');
hold on,scatter(data(101:150,1),data(101:150,2),'go');
```
![](https://raw.githubusercontent.com/whuhan2013/myImage/master/dataImage/chapter10/p8.png)

#### 主成分分析(Princjpal Component Analysis, PCA)      
特征抽取是指通过已有特征的组合（变换）建立一个新的特征子集。在众多的组合方法当中，线性组合（变换）因其计算简单且便于解析分析的特点而显得颇具吸引力。下面就介绍一种通过特征的线性组合来实现降维的方法——主成分分析(principal conponent analysis.PCA)。PCA的实质就是在尽可能好地代表原始数据的前提下， 通过线性变换将高维空间中的样本数据投影到低维空间中       

**具体可参见：**[降维算法学习](http://whuhan2013.github.io/blog/2016/12/13/demension-reduction-learn/)      





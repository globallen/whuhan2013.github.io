---
layout: post
title: 基于PCA和SVM的人脸识别
date: 2017-1-7
categories: blog
tags: [图像处理]
description: 基于PCA和SVM的人脸识别
---

#### svm推广到多类情况     

**一对多的最大响应策略(one against all)**    
假设有A 、B、C.. D四类样本需要划分。在抽取训练集的时候，分别按照如下4种方式划分。    

- A. 所对应的样本特征向量作为正集（类标签为+1), B、C、D所对应的样本特征向量作为负集（类标签为-1).         
- B所对应的样本特征向量作为正集，A. C. D所对应的样本特征向量作为负集       
- C所对应的样本特征向量作为正集， A. B, D所对应的样本特征向量作为负集．
- D所对应的样本特征向量作为正集， A. B、 C所对应的样本特征向量作为负集．  

对上述4个训练集分别进行训练， 得到4个SVM分类器。在测试的时候， 把未知类别的测试样本又分别送入这4个分类器进行判决,取最大值    

**一对一的投票策略(one against one 叶th voting)**      
将A. B、C, D四类样本两类两类地组成训练集， 即(A,B)、(A.C)、(A,D)、(B,C)、(B,D)、{C,D), 得到6个（对于n类问题， 为n(n-1)/2个） SVM二分器。在测试的时候，把测试样本又依次送入这6个二分类器， 采取投票形式， 最后得到一组结果。投票是以如下方式进行的。

初始化： vote(A)= vote(B)= vote(C)= vote{D)=O。        
投票过程：如果使用训练集(A,B)得到的分类器将f判定为A类，则vote(:A)=vote(A)+ 1 , 否则vote(B)=vote(B)+ 1; 如果使用(A,C)训练的分类器将又判定为A类，则vote(.4.)=vote(A)+ 1, 否则vote(C)=vote(C)+l; . ….. ; 如果使用(C,D)训练的分类器将又判定为C类，则
vote(C)=vote(C)+ 1 , 否则vote(D)=vote(D)+ 1。         
最终判决： Max(vote(A), vote(B), vote{C), vote(D))。如有两个以上的最大值， 则一般可简单地取第一个最大值所对应的类别。    

**3. 一对一的淘汰策略(one against one with. eUmlnating)**      
这是在文献中专门针对SVM提出的一种多类推广策略，实际上它也适用于所有可以提供分类器置信度信息的二分器。该方法同样基于一对一判别策略解决多类问题， 对于这4类问题， 需训练6个分类器(A,.B)、(A,C)、(A,D）、(B,C)、(B,D)、(C,D)。显然， 对于这4类中的任意一类， 如第A类中的某一样本， 就可由(A,B）、(A,C)、(A,D)这3个二分器中的任意一个来识别，即判别函数间存在冗余。于是我们将这些二分器根据其置信度从大到小排序，置信度越大表示此二分器分类的结果越可靠， 反之则越有可能出现误判。对这6个分类器按其置信度由大到小排序并分别编号， 假设为1 # (A,C), 2# (A,B）， 3#(A,D)., 4# (B,D), 5# (C,D), 6# (B,C) 。  

此时， 判别过程如下。       
(1) 设被识别对象为X, 首先由1#判别函数进行识别。若判别函数h(x) = +1, 则结果为类型A, 所有关于类型C的判别函数均被淘汰；若判别函数h(x) =-1, 则结果为类型C,所有关于类型A的判别函数均被淘汰；若判别函数h(x) = 0, 为“ 拒绝决策” 的情形， 则直接选用2#判别函数进行识别。   
(2)被识别对象x再由4#判别函数进行识别。若结果为类型+1, 淘汰所有关于D类的判别函数， 则所剩判别函数为6# (B,C)。          
(3) 被识别对象x再由6#判别函数进行识别。若得到结果为类型+1 则可判定最终的分类结果为B。  

那么， 如何来表示置信度呢？对于SVM而言，分割超平面的分类间隔越大，就说明两类样本越容易分开，表明了问题本身较好的可分性。因此可以用各个SVM二分器的分类间隔大小作为其置信度。     


隔大小作为其置信度。
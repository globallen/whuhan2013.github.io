---
layout: post
title: 车牌识别之文字定位
date: 2017-2-3
categories: blog
tags: [Opencv]
description: mser
---

本文主要介绍车牌定位中的一种新方法--文字定位方法（MSER）。          

**文字定位法**       
文字定位方法是采用了低级过滤器提取文字，然后再将其组合的一种定位方法。原先是利用在场景中定位文字，在这里利用其定位车牌。与在扫描文档中的文字不同，自然场景中的文字具有低对比度，背景各异，光亮干扰较多等情况，因此需要一个极为鲁棒的方法去提取出来。目前业界用的较多的是MSER（最大稳定极值区域）方法。EasyPR使用的是MSER的一个改良方法，专门针对文字进行了优化。在文字定位出来以后，一般需要用一个分类器将其中大部分的定位错误的文字去掉，例如ANN模型。为了获得最终的车牌，这些文字需要组合起来。由于实际情况的复杂，简单的使用普通的聚类效果往往不好，因此EasyPR使用了一种鲁棒性较强的种子生长方法（seed growing）去组合。   

[MSER算法介绍](http://blog.csdn.net/pirlck/article/details/52846550)   

首先通过MSER提取区域，提取出的区域进行一个尺寸判断，滤除明显不符合车牌文字尺寸的。接下来使用一个文字分类器，将分类结果概率大于0.9的设为强种子（下图的绿色方框）。靠近的强种子进行聚合，划出一条线穿过它们的中心（图中白色的线）。一般来说，这条线就是车牌的中间轴线，斜率什么都相同。之后，就在这条线的附近寻找那些概率低于0.9的弱种子（蓝色方框）。由于车牌的特征，这些蓝色方框应该跟绿色方框距离不太远，同时尺寸也不会相差太大。蓝色方框实在绿色方框的左右查找的，有时候，几个绿色方框中间可能存在着一个方库，这可以通过每个方框之间的距离差推出来，这就是橙色的方框。全部找完以后。绿色方框加上蓝色与橙色方框的总数代表着目前在车牌区域中发现的文字数。有时这个数会低于7（中文车牌的文字数），这是因为有些区域即便通过MSER也提取不到（例如非常不稳定或光照变化大的），另外很多中文也无法通过MSER提取到（中文大多是不连通的，MSER提取的区域基本都是连通的）。所以下面需要再增加一个滑动窗口（红色方框）来寻找这些缺失的文字或者中文，如果分类器概率大于某个阈值，就可以将其加入到最终的结果中。最后，把所有文字的位置用一个方框框起来，就是车牌的区域。

　　想要通过中间图片进行调试程序的话，首先依次根据函数调用关系plateMserLocate->mserSearch->mserCharMatch在core_func.cpp找到位置。在函数的最后，把图片输出的判断符改为1。然后在resources/image下面依次新建tmp与plateDetect目录（跟代码中的一致），接下来再运行时在新目录里就可以看到这些调试图片。

![](http://images2015.cnblogs.com/blog/673793/201607/673793-20160705114756686-1108839327.jpg)

#### 更加合理准确的评价指标

　　原先的EasyPR的评价标准中有很多不合理的地方。例如一张图片中找到了一个疑似的区域，就认为是定位成功了。或者如果一张图片中定位到了几个车牌，就用差距率最小的那个作为定位结果。这些地方不合理的地方在于，有可能找到的疑似区域根本不是车牌区域。另外一个包含几个车牌的图片仅仅用最大的一个作为结果，明显不合理。

　　因此新评价指标需要考虑定位区域和车牌区域的位置差异，只有当两者接近时才能认为是定位成功。另外，一张图片如果有几个车牌，对应的就有几个定位区域，每个区域与车牌做比对，综合起来才能作为定位效果。因此需要加入一个GroundTruth，标记各个车牌的位置信息。新版本中，我们标记了251张图片，其中共250个车牌的位置信息。为了衡量定位区域与车牌区域的位置差的比例，又引入了ICDAR2003的评价协议，来最终计算出定位的recall，precise与fscore值。

　　车牌定位评价中做了大改动。字符识别模块则做了小改动。首先是去除了“平均字符差距”这个意义较小的指标。转而用零字符差距，一字符差距，中文字符正确替代，这三者都是比率。零字符差距（0-error）指的是识别结果与车牌没有任何差异，跟原先的评价协议中的“完全正确率”指代一样。一字符差距（1-error）指的是错别仅仅只有1个字符或以下的，包括零字符差距。注意，中文一般是两个字符。中文字符正确（Chinese-precise）指代中文字符识别正确的比率。这三个指标，都是越大越好，100%最高。

#### 非极大值抑制    
　　新版本中另一个较大的改动就是大量的使用了非极大值抑制(Non-maximum suppression)。使用非极大值抑制有几个好处：1.当有几个定位区域重叠时，可以根据它们的置信度（也是SVM车牌判断模型得出的值）来取出其中最大概率准确的一个，移除其他几个。这样，不同定位方法，例如Sobel与Color定位的同一个区域，只有一个可以保留。因此，EasyPR新版本中，最终定位出的一个车牌区域，不再会有几个框了。2.结合滑动窗口，可以用其来准确定位文字的位置，例如在车牌定位模块中找到概率最大的文字位置，或者在文字识别模块中，更准确的找到中文文字的位置。    
[非极大值抑制算法](http://www.cnblogs.com/liekkas0626/p/5219244.html)           
[非极大值抑制（Non-maximum suppression）在物体检测领域的应用](http://blog.csdn.net/pb09013037/article/details/45477591)

　　非极大值抑制的使用使得EasyPR的定位方法与后面的识别模块解耦了。以前，每增加定位方法，可能会对最终输出产生影响。现在，无论多少定位方法定位出的车牌都会通过非极大值抑制取出最大概率的一个，对后面的方法没有一点影响。

　　另外，如今setMaxPlates（）这个函数可以确实的作用了。以前可以设置，但没效果。现在，设置这个值为n以后，当在一副图像中检测到大于n个车牌区域（注意，这个是经过非极大值抑制后的）时，EasyPR只会输出n个可能性最高的车牌区域。

#### 字符分割与识别部分的强化      
　　新版本中字符分割与识别部分都添加了新算法。例如使用了spatial-ostu替代普通的ostu算法，增加了图像分割在面对光照不均匀的图像上的二值化效果。
   
<center><img src="http://images2015.cnblogs.com/blog/673793/201607/673793-20160703120322906-1969744626.jpg"></center>
同时，识别部分针对中文增加了一种adaptive threshold方法。这种方法在二值化“川”字时有比ostu更好的效果。通过将两者一并使用，并选择其中字符识别概率最大的一个，显著提升了中文字符的识别准确率。在识别中文时，增加了一个小型的滑动窗口，以此来弥补通过省份字符直接查找中文字符时的定位不精等现象。


#### 新的特征与SVM模型，新的中文识别ANN模型

　　为了强化车牌判断的鲁棒性，新版本中更改了SVM模型的特征，使用LBP特征的模型在面对低对比度与光照的车牌图像中也有很好的判断效果。为了强化中文识别的准确率，现在单独为31类中文文字训练了一个ANN模型ann_chinese，使用这个模型在分类中文是的效果，相对原先的通用模型可以提升近10个百分点。


